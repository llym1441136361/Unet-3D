import argparse
import logging
import sys
from pathlib import Path
import numpy as np

import torch
import torch.nn as nn
import torch.nn.functional as F
import wandb
from torch import optim
from torch.utils.data import DataLoader, random_split
from tqdm import tqdm

from dataloader import Brats21Dataset
from modules2.Unet3D_res_at_da3 import UNet3D
from utils.Focalloss import FocalLoss
from utils.FocalLoss2 import MultiCEFocalLoss
from evaluate import evaluate
from utils.utils import Loss

dir_checkpoint = Path('/root/autodl-tmp/traindata/') #每轮训练保存的参数目录


def reshape_m(true_masks):
    [n, _, h, w, d] = true_masks.shape
    new_label_masks = np.zeros([n, h, w, d])
    for label_id in range(n):
        label_mask = true_masks[label_id].cpu().numpy()
        [ori_c, ori_d, ori_h, ori_w] = label_mask.shape
        label_mask = np.reshape(label_mask, [ori_d, ori_h, ori_w])
        new_label_masks[label_id] = label_mask
    return new_label_masks


def train_net(net1,
              # net2,
              device,
              epochs: int = 5,
              batch_size: int = 1,
              learning_rate1: float = 1e-2,
              learning_rate2: float = 6e-3,
              val_percent: float = 0.1,
              save_checkpoint: bool = True,
              amp: bool = False,
              n_classes=3,
              decay: bool = False):
    # 1. Create dataset
    dataset = Brats21Dataset(
        '/root/Unet/datalist.txt')  # 读取数据集列表文件

    # 2. Split into train / validation partitions
    n_val = 200
    n_train = 1000
    train_set, val_set = random_split(dataset, [n_train, n_val], generator=torch.Generator().manual_seed(0))

    # 3. Create data loaders
    loader_args = dict(batch_size=batch_size, prefetch_factor=2, num_workers=15, pin_memory=True)
    train_loader = DataLoader(train_set, shuffle=True, **loader_args)
    val_loader = DataLoader(val_set, shuffle=False, drop_last=True, **loader_args)

    # (Initialize logging)
    experiment = wandb.init(project='3DUNet', resume='allow', anonymous='must')
    experiment.config.update(dict(epochs=epochs, batch_size=batch_size, learning_rate1=learning_rate1,
                                  learning_rate2=learning_rate2, val_percent=val_percent,
                                  save_checkpoint=save_checkpoint,
                                  amp=amp))

    logging.info(f'''Starting training:
        Epochs:          {epochs}
        Batch size:      {batch_size}
        Learning rate1:  {learning_rate1}
        Training size:   {n_train}
        Validation size: {n_val}
        Checkpoints:     {save_checkpoint}
        Device:          {device.type}
        Mixed Precision: {amp}
        Decay:           {decay}
    ''')

    # 4. Set up the optimizer, the loss, the learning rate scheduler and the loss scaling for AMP
    optimizer1 = optim.AdamW(net1.parameters(), lr=learning_rate1, weight_decay=0, eps=1e-4)
    # optimizer1 = optim.SGD(net1.parameters(),momentum=0.9, lr=learning_rate1, weight_decay=5e-4)
    scheduler1 = optim.lr_scheduler.ReduceLROnPlateau(optimizer1, 'max', factor=0.5, patience=10)
    # optimizer2 = optim.AdamW(net2.parameters(), lr=learning_rate2)
    # scheduler2 = optim.lr_scheduler.ReduceLROnPlateau(optimizer1, 'max', factor=0.5,
    #                                                   patience=8)
    grad_scaler1 = torch.cuda.amp.GradScaler(enabled=amp)
    # grad_scaler2 = torch.cuda.amp.GradScaler(enabled=amp)
    alpha1 = torch.tensor([1.0, 500.0, 200.0, 300.0])
    # alpha2 = torch.tensor([1.0, 150])
    # criterion = MultiCEFocalLoss(class_num=n_classes, alpha=alpha, gamma=3).to(device)
    # criterion1 = nn.CrossEntropyLoss(weight=alpha1).to(device)
    criterion1 = Loss(n_classes=4, weight=alpha1).to(device)
    # criterion2 = nn.CrossEntropyLoss(weight=alpha2).to(device)
    # criterion1 = FocalLoss(alpha=alpha1, gamma=2, weight=1).to(device)
    # criterion2 = FocalLoss(alpha=alpha2, gamma=3).to(device)
    global_step = 0
    val_scoremax0 = 0
    val_scoremax1 = 0
    val_scoremax2 = 0
    val_scoremax3 = 0
    # 5. Begin training
    for epoch in range(1, epochs + 1):
        net1.train()
        # net2.train()
        epoch_loss1 = 0
        epoch_loss2 = 0
        with tqdm(total=n_train, desc=f'Epoch {epoch}/{epochs}', unit='img') as pbar:
            for i, batch in enumerate(train_loader):
                volumes1, volumes2, volumes3, volumes4, true_masks0, true_masks1, true_masks2 = batch
                images1 = torch.cat((volumes1, volumes2, volumes3, volumes4), dim=1)
                # images2 = volumes4

                images1 = images1.to(device=device, dtype=torch.float32, non_blocking=True)
                # images2 = images2.to(device=device, dtype=torch.float32, non_blocking=True)

                true_masks1 = true_masks0.to(device=device, dtype=torch.long, non_blocking=True)
                new_label_masks1 = reshape_m(true_masks1)
                new_label_masks1[new_label_masks1 == 4] = 3
                # new_label_masks2 = reshape_m(true_masks2)
                new_label_masks_t1 = torch.tensor(new_label_masks1).to(device=device, dtype=torch.long, non_blocking=True)
                # new_label_masks_t2 = torch.tensor(new_label_masks2).to(device=device, dtype=torch.long, non_blocking=True)
                # new_label_masks[np.where(new_label_masks == 0)] = alpha[0]
                # new_label_masks[np.where(new_label_masks == 1)] = alpha[1]
                # new_label_masks[np.where(new_label_masks == 2)] = alpha[2]
                # new_label_masks[np.where(new_label_masks == 3)] = alpha[3]
                # balanced = torch.tensor(new_label_masks).to(device=device, non_blocking=True)
                # new_label_masks = F.one_hot(new_label_masks, n_classes).permute(0, 4, 1, 2, 3).float()
                with torch.cuda.amp.autocast(enabled=amp):
                    masks_pred1 = net1(images1)
                    # masks_pred2 = net2(images2)
                    loss1 = criterion1(masks_pred1, new_label_masks_t1)
                    # loss2 = criterion2(masks_pred2, new_label_masks_t2)

                grad_scaler1.scale(loss1).backward()
                # grad_scaler2.scale(loss2).backward()
                # if (i + 1) % 5 == 0 or (i + 1) == len(train_loader):
                grad_scaler1.step(optimizer1)
                grad_scaler1.update()
                optimizer1.zero_grad(set_to_none=True)
                    # grad_scaler2.step(optimizer2)
                    # grad_scaler2.update()
                    # optimizer2.zero_grad(set_to_none=True)
                pbar.update(images1.shape[0])
                global_step += 1
                epoch_loss1 += loss1.item()
                # epoch_loss2 += loss2.item()
                experiment.log({
                    'train loss1': loss1.item(),
                    # 'train loss2': loss2.item(),
                    'step': global_step,
                    'epoch': epoch
                })
                pbar.set_postfix(**{'loss1(batch)': loss1.item()}) # , 'loss2(batch)': loss2.item()

                # Evaluation round
                division_step = (n_train // (4 * batch_size))
                if division_step > 0:
                    if global_step % division_step == 0:
                        # histograms = {}
                        # for tag, value in net.named_parameters():
                        #     tag = tag.replace('/', '.')
                        #     if not torch.isinf(value).any():
                        #         histograms['Weights/' + tag] = wandb.Histogram(value.data.cpu())
                        #     if not torch.isinf(value.grad).any():
                        #         histograms['Gradients/' + tag] = wandb.Histogram(value.grad.data.cpu())

                        val_score1 = evaluate(net1, val_loader, device, batch_size, reshape_m) #, val_score2, val_score_sum
                        if decay:
                            scheduler1.step(val_score1[1])
                        # scheduler2.step(val_score2[1])
                        if val_score1[1] > val_scoremax1:
                            val_scoremax1 = val_score1[1]
                            torch.save(net1.state_dict(), '/root/autodl-tmp/trainmax/checkpoint1maxt.pth') #最优解储存位置
                            logging.info(f'Checkpoint{val_scoremax1} saved!')
                        # if val_score2[1] > val_scoremax2:
                        #     val_scoremax2 = val_score2[1]  
                        #     torch.save(net2.state_dict(), '/content/drive/MyDrive/Tasker/trainmax/checkpoint2maxt.pth')
                        #     logging.info(f'Checkpoint{val_scoremax2} saved!')
                        # if val_score1[0] > val_scoremax0:
                        #     val_scoremax0 = val_score1[0]
                        #     torch.save(net1.state_dict(),
                        #                f'/content/drive/MyDrive/Tasker/trainmax/checkpointmax0 {val_score1[0]:.3f} {val_score1[1]:.3f} {val_score1[2]:.3f}.pth')
                        #     logging.info(f'Checkpoint0 {val_scoremax0} saved!')
                        # if val_score1[1] > val_scoremax1:
                        #     val_scoremax1 = val_score1[1]
                        #     torch.save(net1.state_dict(),
                        #                f'/content/drive/MyDrive/Tasker/trainmax/checkpointmax1 {val_score1[0]:.3f} {val_score1[1]:.3f} {val_score1[2]:.3f}.pth')
                        #     logging.info(f'Checkpoint1 {val_scoremax1} saved!')
                        # if val_score1[2] > val_scoremax2:
                        #     val_scoremax2 = val_score1[2]
                        #     torch.save(net1.state_dict(),
                        #                f'/content/drive/MyDrive/Tasker/trainmax/checkpointmax2 {val_score1[0]:.3f} {val_score1[1]:.3f} {val_score1[2]:.3f}.pth')
                        #     logging.info(f'Checkpoint2 {val_scoremax2} saved!')
                        # if val_score[3] > val_scoremax3:
                        #     val_scoremax3 = val_score[3]
                        #     torch.save(net1.state_dict(),
                        #                f'/content/drive/MyDrive/Tasker/trainmax/checkpointmax3 {val_score[0]:.2f} {val_score[1]:.2f} {val_score[2]:.2f} {val_score[3]:.2f}.pth')
                        #     logging.info(f'Checkpoint3 {val_scoremax3} saved!')
                        logging.info(f'Validation Dice score: {val_score1}') # \n{val_score2}\n{val_score_sum}
                        experiment.log({
                            'learning rate1': optimizer1.param_groups[0]['lr'],
                            # 'learning rate2': optimizer2.param_groups[0]['lr'],
                            'validation Dice1-0': val_score1[0],
                            'validation Dice1-1': val_score1[1],
                            'validation Dice1-2': val_score1[2],
                            # 'validation Dice2-0': val_score2[0],
                            # 'validation Dice2-1': val_score2[1],
                            'step': global_step,
                            'epoch': epoch,
                        })

        if save_checkpoint:
            Path(dir_checkpoint).mkdir(parents=True, exist_ok=True)
            torch.save(net1.state_dict(), str(dir_checkpoint / 'checkpoint1_epoch{}.pth'.format(epoch)))
            # torch.save(net2.state_dict(), str(dir_checkpoint / 'checkpoint2_epoch{}.pth'.format(epoch)))
            logging.info(f'Checkpoint {epoch} saved!')


def get_args():
    parser = argparse.ArgumentParser(description='Train the UNet on images and target masks')
    parser.add_argument('--epochs', '-e', metavar='E', type=int, default=50, help='Number of epochs')
    parser.add_argument('--batch-size', '-b', dest='batch_size', metavar='B', type=int, default=3, help='Batch size')
    parser.add_argument('--learning-rate', '-l', metavar='LR', type=float, default=6e-4
                        , help='Learning rate', dest='lr')
    parser.add_argument('--load', '-f', action='store_true', default=False, help='Load model from a .pth file')
    parser.add_argument('--decay', '-d', action='store_true', default=False, help='Load model from a .pth file')
    parser.add_argument('--scale', '-s', type=float, default=0.5, help='Downscaling factor of the images')
    parser.add_argument('--validation', '-v', dest='val', type=float, default=4.0,
                        help='Percent of the data that is used as validation (0-100)')
    parser.add_argument('--amp', action='store_true', default=True, help='Use mixed precision')
    parser.add_argument('--bilinear', action='store_true', default=False, help='Use bilinear upsampling')
    parser.add_argument('--classes', '-c', type=int, default=4, help='Number of classes')
    parser.add_argument('--resume', '-r', dest='resume', type=str, default='/root/autodl-tmp/trainmax/checkpoint1maxt.pth', help='Resume path')
    return parser.parse_args()


if __name__ == '__main__':
    args = get_args()
    resume_path1 = args.resume
    logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    logging.info(f'Using device {device}')
    # checkpoint2 = torch.load(resume_path2, map_location=torch.device('cpu'))
    net1 = UNet3D(4, 4)
    if args.load:
        checkpoint1 = torch.load(resume_path1, map_location=torch.device('cpu'))
        logging.info(f'Model loaded from {resume_path1}')
        net1.load_state_dict(checkpoint1, strict=False)
    # net2 = UNet3D(1, 2)
    # net2.load_state_dict(checkpoint2, strict=False)
    logging.info(f'Network1:\n'
                 f'{net1.in_channels} input channels\n'
                 f'{net1.num_classes} output channels (classes)\n')
    # logging.info(f'Network2:\n'
    #              f'{net2.n_channels} input channels\n'
    #              f'{net2.n_classes} output channels (classes)\n')
    net1.to(device=device)
    # net2.to(device=device)
    try:
        train_net(net1=net1,
                  # net2=net2,
                  epochs=args.epochs,
                  batch_size=args.batch_size,
                  device=device,
                  val_percent=args.val / 100,
                  amp=args.amp,
                  n_classes=net1.num_classes,
                  learning_rate1=args.lr,
                  decay=args.decay)
    except KeyboardInterrupt:
        torch.save(net1.state_dict(), 'INTERRUPTED1.pth')
        # torch.save(net2.state_dict(), 'INTERRUPTED2.pth')
        logging.info('Saved interrupt')
        raise
